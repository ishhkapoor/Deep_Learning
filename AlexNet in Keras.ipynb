{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c11bd63a",
   "metadata": {},
   "source": [
    "## Let's construct AlexNet in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dfb0dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 22s 0us/step\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# Loads the CIFAR dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Display our data shape/dimensions\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Now we one hot encode outputs\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c54ad",
   "metadata": {},
   "source": [
    "## Now let's create our layers to replicate AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f26829ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 96)        34944     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 32, 32, 96)        384       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 96)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 16, 16, 96)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 256)       614656    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 16, 16, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " zero_padding2d (ZeroPaddin  (None, 10, 10, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 512)       1180160   \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 10, 10, 512)       2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 10, 10, 512)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 5, 5, 512)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " zero_padding2d_1 (ZeroPadd  (None, 7, 7, 512)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 7, 7, 1024)        4719616   \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 7, 7, 1024)        4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " zero_padding2d_2 (ZeroPadd  (None, 9, 9, 1024)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 9, 9, 1024)        9438208   \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 9, 9, 1024)        4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 9, 9, 1024)        0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 4, 4, 1024)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3072)              50334720  \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 3072)              12288     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 3072)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              12587008  \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 4096)              16384     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                40970     \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 10)                40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78990642 (301.33 MB)\n",
      "Trainable params: 78970462 (301.25 MB)\n",
      "Non-trainable params: 20180 (78.83 KB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "l2_reg = 0\n",
    "\n",
    "# Initialize model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Conv Layer \n",
    "model.add(Conv2D(96, (11, 11), input_shape=x_train.shape[1:],\n",
    "    padding='same', kernel_regularizer=l2(l2_reg)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 2nd Conv Layer \n",
    "model.add(Conv2D(256, (5, 5), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 3rd Conv Layer \n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 4th Conv Layer \n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(1024, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 5th Conv Layer \n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(1024, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 1st FC Layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3072))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 2nd FC Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 3rd FC Layer\n",
    "model.add(Dense(num_classes))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = keras.optimizers.Adadelta(),\n",
    "              metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b53b5d",
   "metadata": {},
   "source": [
    "## Now let us train AlexNet on our CIFAR10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122e6796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      " 168/1563 [==>...........................] - ETA: 50:26 - loss: 2.4725 - accuracy: 0.1475"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "batch_size = 32\n",
    "epochs = 1\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          shuffle=True)\n",
    "\n",
    "model.save(\"Trained Models/CIFAR10_AlexNet_1_Epoch.h5\")\n",
    "\n",
    "# Evaluate the performance of our trained model\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
