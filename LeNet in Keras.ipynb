{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1WBLeZDvu9P"
      },
      "source": [
        "### Let's construct LeNet in Keras!\n",
        "\n",
        "#### First let's load and prep our MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmwrEK9Pvu9R",
        "outputId": "030934e8-74c6-4582-b72d-3dbc544b5b11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/ZeroPadding2D\n",
        "# ZeroPadding2D This layer can add rows and columns of zeros at the top, bottom, left and right side of an image tensor\n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "import keras\n",
        "\n",
        "# loads the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test)  = mnist.load_data()\n",
        "\n",
        "# Lets store the number of rows and columns\n",
        "img_rows = x_train[0].shape[0]\n",
        "img_cols = x_train[1].shape[0]\n",
        "\n",
        "# Getting our date in the right 'shape' needed for Keras\n",
        "# We need to add a 4th dimenion to our data thereby changing our\n",
        "# Our original image shape of (60000,28,28) to (60000,28,28,1)\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "# store the shape of a single image\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# change our image type to float32 data type\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Normalize our data by changing the range from (0 to 255) to (0 to 1)\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Now we one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "num_classes = y_test.shape[1]\n",
        "num_pixels = x_train.shape[1] * x_train.shape[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49yz9Fl0vu9S"
      },
      "source": [
        "### Now let's create our layers to replicate LeNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtcJVw8bvu9S",
        "outputId": "6538ac85-65bf-49d4-ca48-c0beb13e0778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 20)        520       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 28, 28, 20)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 20)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 50)        25050     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 14, 14, 50)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 7, 7, 50)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2450)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 500)               1225500   \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 500)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5010      \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,256,080\n",
            "Trainable params: 1,256,080\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        "\n",
        "# 2 sets of CRP (Convolution, RELU, Pooling)\n",
        "model.add(Conv2D(20, (5, 5),\n",
        "                 padding = \"same\",\n",
        "                 input_shape = input_shape))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
        "\n",
        "model.add(Conv2D(50, (5, 5),\n",
        "                 padding = \"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
        "\n",
        "# Fully connected layers (w/ RELU)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "# Softmax (for classification)\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = keras.optimizers.Adadelta(),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HpmLFeqvu9T"
      },
      "source": [
        "### Now let us train LeNet on our MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kW8gktcvu9T",
        "outputId": "ea52cca7-05e8-49f2-9b23-ee5f803eed0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 134s 283ms/step - loss: 2.2934 - accuracy: 0.1300 - val_loss: 2.2724 - val_accuracy: 0.2008\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 129s 274ms/step - loss: 2.2518 - accuracy: 0.2840 - val_loss: 2.2277 - val_accuracy: 0.3976\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 132s 282ms/step - loss: 2.2029 - accuracy: 0.5046 - val_loss: 2.1716 - val_accuracy: 0.5835\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 132s 282ms/step - loss: 2.1388 - accuracy: 0.6216 - val_loss: 2.0960 - val_accuracy: 0.6574\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 133s 284ms/step - loss: 2.0511 - accuracy: 0.6812 - val_loss: 1.9907 - val_accuracy: 0.7046\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 128s 273ms/step - loss: 1.9286 - accuracy: 0.7152 - val_loss: 1.8444 - val_accuracy: 0.7318\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 128s 273ms/step - loss: 1.7617 - accuracy: 0.7350 - val_loss: 1.6501 - val_accuracy: 0.7500\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 130s 278ms/step - loss: 1.5517 - accuracy: 0.7502 - val_loss: 1.4199 - val_accuracy: 0.7677\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 130s 278ms/step - loss: 1.3231 - accuracy: 0.7669 - val_loss: 1.1921 - val_accuracy: 0.7857\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 130s 277ms/step - loss: 1.1148 - accuracy: 0.7814 - val_loss: 1.0010 - val_accuracy: 0.8033\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 1.0010 - accuracy: 0.8033\n",
            "Test loss: 1.0010381937026978\n",
            "Test accuracy: 0.8033000230789185\n"
          ]
        }
      ],
      "source": [
        "# Training Parameters\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          shuffle=True)\n",
        "\n",
        "model.save(\"Trained Models/mnist_LeNet.h5\")\n",
        "\n",
        "# Evaluate the performance of our trained model\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}